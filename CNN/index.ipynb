{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887015fe-378c-4ee5-976b-e8ae7ec00ff7",
   "metadata": {},
   "source": [
    "# PyTorch Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0780a-3141-409a-9561-48ee89a0c23e",
   "metadata": {},
   "source": [
    "## Setting up and Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48cd92b-c4ec-4d48-8b8c-558662215d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "# Ignore deprecated warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66fe710-2d62-41db-a41c-dafd6d4e5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe458414-7618-4ac0-9d8e-721f837fa739",
   "metadata": {},
   "source": [
    "## Analyzing and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c559b-b8e1-4867-993a-d4c6a807e0a2",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d6afdd-8712-4370-9479-b7c4072d7cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3602824-becb-4a16-a363-ade4f22afe70",
   "metadata": {},
   "source": [
    "### Testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53090af-542c-4c5a-b6ef-e565f98b7fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e5ed9-aead-4a78-889e-55f67952fad0",
   "metadata": {},
   "source": [
    "### Dataset Shape and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef37340f-9bee-4494-b0c4-100b146766ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "898fb260-146b-4e7b-8438-db63dc3ca54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72a4698-b3aa-4aa7-8d8a-6d121a0650cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88725e49-1f50-45d5-840a-478b7f466226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe88220-a8c3-4822-b63f-5ea987db422f",
   "metadata": {},
   "source": [
    "### MNIST Dataset Description\n",
    "\n",
    "The MNIST (Modified National Institute of Standards and Technology) dataset is a widely-used dataset in the field of machine learning and computer vision. It consists of a collection of handwritten digits, from 0 to 9, and serves as a benchmark for developing and testing machine learning algorithms. The dataset was created from samples of handwritten digits by high school students and employees of the United States Census Bureau.\n",
    "\n",
    "#### Dataset Details\n",
    "\n",
    "- **Number of Classes:** 10 (Digits 0 through 9)\n",
    "- **Image Size:** 28 x 28 pixels\n",
    "- **Number of Samples:**\n",
    "  - Training Set: 60,000 images\n",
    "  - Test Set: 10,000 images\n",
    "- **Data Split:**\n",
    "  - The dataset is divided into two main parts: a training set and a test set.\n",
    "- **Format:**\n",
    "  - Each image is grayscale, with pixel values ranging from 0 (black) to 255 (white).\n",
    "  - The dataset is structured as a collection of 28x28-pixel images.\n",
    "- **Labeling:**\n",
    "  - Each image is associated with a corresponding label indicating the digit it represents.\n",
    "- **Purpose:**\n",
    "  - The MNIST dataset is commonly used for training and evaluating machine learning models, especially for tasks related to image classification, digit recognition, and deep learning.\n",
    "- **Usage:**\n",
    "  - Researchers and practitioners often use MNIST as a benchmark dataset to develop, validate, and compare image classification algorithms and deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a23232-85ba-4efa-9924-f0870781b678",
   "metadata": {},
   "source": [
    "## Creating Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5e7de4-4e33-489e-a565-76c1d361a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : DataLoader(train_data,\n",
    "                         batch_size=100,\n",
    "                         shuffle=True,\n",
    "                         num_workers=1),\n",
    "    'test' : DataLoader(test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba667e7-def1-4d15-8a68-853ceb71892d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x17468e8d0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x174676b50>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67478bfa-2817-4794-b009-3aff4085354f",
   "metadata": {},
   "source": [
    "I'm here to provide an explanation as requested in the first-person point of view:\n",
    "\n",
    "I created the `loaders` dictionary in my code to manage the data loading process for my machine learning project. Here's why I did this:\n",
    "\n",
    "1. **Data Loading Module**: First, I imported the `DataLoader` class from PyTorch's `torch.utils.data` module. This class is essential for efficiently loading and managing my training and testing datasets.\n",
    "\n",
    "2. **Data Split**: In my project, I have two sets of data: a training dataset (`train_data`) and a testing dataset (`test_data`). I need to split these datasets into batches for processing during training and testing.\n",
    "\n",
    "3. **Loaders for Training and Testing**: I created two data loaders within the `loaders` dictionary: one for training data and one for testing data. Here's what each loader does:\n",
    "\n",
    "   - `train` DataLoader:\n",
    "     - I configured this DataLoader for the training dataset (`train_data`).\n",
    "     - I specified a batch size of 100. This means that during training, my model will process the data in mini-batches of 100 samples at a time, which is an efficient way to update the model's parameters.\n",
    "     - I set `shuffle` to `True`, which means that the training data will be shuffled at the beginning of each epoch. Shuffling helps prevent the model from memorizing the order of the data and aids in better generalization.\n",
    "     - I used `num_workers` with a value of 1. This means that I will use a single worker process for data loading. This is usually sufficient for most tasks. More workers can be used to load data faster if needed, but it depends on the available system resources.\n",
    "\n",
    "   - `test` DataLoader:\n",
    "     - Similarly, I configured this DataLoader for the testing dataset (`test_data`).\n",
    "     - The batch size is set to 100, ensuring that I evaluate the model's performance on 100 samples at a time.\n",
    "     - Like the training DataLoader, I set `shuffle` to `True` to randomize the order of test data.\n",
    "     - I also used a single worker for test data loading.\n",
    "\n",
    "In summary, I created these data loaders to efficiently process and manage my training and testing data in batches, making it easier to train and evaluate machine learning models. The choice of batch size, shuffling, and the number of workers depends on the specific requirements of my project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f3a8d-b228-4805-81fd-a6e8673b981d",
   "metadata": {},
   "source": [
    "## Creating the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0dee3b-8485-4605-b814-f200bad1532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219bb8d6-5ec5-49a0-b172-c090ec3fe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca83f3-9d09-4a9e-a9c2-7c7457c32d9b",
   "metadata": {},
   "source": [
    "## Why did I created the CNN Machine Learning Model using PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b45c23-20de-4879-8701-5d49390e6617",
   "metadata": {},
   "source": [
    "\n",
    "As I embark on the journey to analyze the MNIST dataset, I've chosen to work with PyTorch and employ a Convolutional Neural Network (CNN) for a few compelling reasons.\n",
    "\n",
    "## Why I Chose PyTorch\n",
    "\n",
    "1. **Ease of Use and Flexibility:** PyTorch is known for its user-friendly and dynamic computation graph, making it an excellent choice for deep learning research and experimentation. As I explore the MNIST dataset, PyTorch's flexibility allows me to define and modify complex neural network architectures with ease.\n",
    "\n",
    "2. **Rich Ecosystem:** PyTorch offers a rich ecosystem of tools and libraries for machine learning and deep learning, including `torchvision`, which provides easy access to popular datasets like MNIST, as well as pre-processing tools and data augmentation techniques.\n",
    "\n",
    "3. **Community and Documentation:** PyTorch has a vibrant and supportive community. Extensive documentation, tutorials, and online forums provide valuable resources as I delve into the intricacies of deep learning and image classification.\n",
    "\n",
    "4. **GPU Acceleration:** PyTorch seamlessly integrates with GPUs, enabling me to leverage the power of accelerated computing for faster training and better model performance.\n",
    "\n",
    "## Why I Chose a Convolutional Neural Network (CNN)\n",
    "\n",
    "1. **Specialized for Image Data:** CNNs are designed for image-related tasks, and the MNIST dataset consists of 28x28 pixel grayscale images of handwritten digits. CNNs excel at capturing hierarchical patterns and features in images, making them a natural choice for this task.\n",
    "\n",
    "2. **Feature Learning:** CNNs automatically learn and extract hierarchical features from the input data. This feature learning capability allows me to focus on the architecture and let the network discover the relevant patterns within the images.\n",
    "\n",
    "3. **Spatial Hierarchy:** CNNs preserve the spatial hierarchy of the input data, which is essential for recognizing intricate patterns and structures in images. In the case of handwritten digits, preserving the spatial relationships of pixels is crucial for accurate recognition.\n",
    "\n",
    "4. **Weight Sharing:** CNNs utilize weight sharing to reduce the number of parameters, making them more efficient for image data. This is particularly beneficial when working with relatively smalnetwork\n",
    "        return F.softmax(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04987a4-7803-4e9f-9e42-8730ab90732b",
   "metadata": {},
   "source": [
    "## Optimizing the Machine Learning Model using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee66ba8c-b19f-46c4-a1fa-469ad1ca6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1e742-05ea-4955-baba-d64e2c994e72",
   "metadata": {},
   "source": [
    "The code performs the following tasks:\n",
    "\n",
    "1. It imports the PyTorch library using `import torch`.\n",
    "\n",
    "2. It checks if a CUDA-compatible GPU is available using `torch.cuda.is_available()`. If a GPU is available, the code assigns the device to the GPU (`'cuda'`); otherwise, it assigns the device to the CPU (`'cpu'`). This allows the model and data to be processed on the available hardware.\n",
    "\n",
    "3. It creates an instance of the CNN model using `model = CNN()`. This model is designed for image classification tasks and is intended to recognize handwritten digits. The model is then moved to the specified device (GPU or CPU) using `.to(device)`.\n",
    "\n",
    "4. It sets up the optimizer for training the model. In this case, it uses the Adam optimizer (`optim.Adam`) and specifies a learning rate of 0.001. The optimizer is responsible for updating the model's parameters during training.\n",
    "\n",
    "5. It defines the loss function for the model. The code uses the cross-entropy loss (`nn.CrossEntropyLoss()`), which is a common choice for classification tasks. This loss function quantifies the difference between the predicted class probabilities and the actual target labels.\n",
    "\n",
    "These steps are crucial for setting up the model, training it, and optimizing its parameters during the training process. The choice of GPU or CPU depends on the availability of hardware and the speed of processing required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a65db-e00e-440b-b25e-cc0cdaa37201",
   "metadata": {},
   "source": [
    "## Creating the Dataset Training Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34ba35af-f3aa-4222-b294-d1c77386e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)} / {len(loaders['train'].dataset)} ({100 * batch_idx / len(loaders['train']):0f}%)]\\t{loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b54ba-16cd-4a80-8e6f-ff0ba422001f",
   "metadata": {},
   "source": [
    "I implemented the `train` function in my code, and I'll explain why I did this:\n",
    "\n",
    "1. **Model Training Purpose**: I used the `train` function to handle the training process for my machine learning model. Here's why I implemented this function:\n",
    "\n",
    "2. **Set Model State**: I started by setting the model's state to training mode using `model.train()`. This is necessary because some layers, like dropout and batch normalization, behave differently during training and testing. Setting the model to training mode ensures that these layers operate as expected during training.\n",
    "\n",
    "3. **Data Iteration**: I used a `for` loop to iterate through the training data. The loop, defined by `for batch_idx, (data, target) in enumerate(loaders['train']):`, allows me to process the data in batches.\n",
    "\n",
    "4. **Data Transfer to GPU**: To leverage the GPU for faster computation (if available), I transferred both the input data and target labels to the device (either 'cuda' if GPU is available or 'cpu') using `data, target = data.to(device), target.to(device)`.\n",
    "\n",
    "5. **Gradient Initialization**: Before calculating gradients, I initialized the optimizer's gradients to zero with `optimizer.zero_grad()`. This step is crucial because it ensures that gradients from previous iterations do not accumulate.\n",
    "\n",
    "6. **Forward Pass**: I then performed a forward pass through the model by calling `model(data)`. This computes the model's predictions based on the input data.\n",
    "\n",
    "7. **Loss Calculation**: After obtaining model predictions, I calculated the loss between these predictions and the actual target labels using the specified loss function (`loss_fn`). This loss quantifies how well the model is performing on the given batch of data.\n",
    "\n",
    "8. **Backpropagation**: To train the model, I performed backpropagation by calling `loss.backward()`. This step computes the gradients of the loss with respect to the model's parameters.\n",
    "\n",
    "9. **Parameter Updates**: I updated the model's parameters by calling `optimizer.step()`. This step is responsible for adjusting the model's weights to minimize the loss.\n",
    "\n",
    "10. **Progress Reporting**: To keep track of training progress, I included a conditional statement that prints training progress updates every 20 batches. These updates include the current epoch, the number of processed samples, the total dataset size, and the current batch's loss.\n",
    "\n",
    "In summary, I created the `train` function to encapsulate the training logic for my model. This function ensures that the model iteratively processes batches of training data, computes gradients, updates model parameters, and reports training progress. By structuring the training process this way, I can easily manage and monitor the training of my machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77e86f-679b-4e69-ae42-a12862682395",
   "metadata": {},
   "source": [
    "## Creating the Dataset Testing Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1c7f9a-ef83-4618-a2f3-61e4491c25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss: 0.4f}, Accuracy {correct}/{len(loaders['test'].dataset)}  ({100 * correct / len(loaders['test'].dataset):.0f}%\\n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2968b56-0afc-4569-b47f-d45974f5fb14",
   "metadata": {},
   "source": [
    "I implemented the `test` function in my code, and I'll explain why I did this using the first-person point of view:\n",
    "\n",
    "1. **Model Evaluation Purpose**: I created the `test` function to handle the evaluation of my machine learning model. Here's why I implemented this function:\n",
    "\n",
    "2. **Set Model State**: I started by setting the model's state to evaluation mode using `model.eval()`. It's essential to do this because during evaluation, I don't want the model to perform operations like dropout, which are active during training. Setting the model to evaluation mode ensures that these operations are deactivated.\n",
    "\n",
    "3. **Initialize Evaluation Variables**: I initialized variables `test_loss` to keep track of the cumulative test loss and `correct` to count the number of correct predictions made by the model.\n",
    "\n",
    "4. **No Gradient Computation**: Inside the `with torch.no_grad():` context, I specified that no gradients should be computed. This is because I don't need to backpropagate during evaluation, and disabling gradient computation improves efficiency.\n",
    "\n",
    "5. **Data Iteration**: I used a `for` loop to iterate through the test data using `for data, target in loaders['test']:`. This loop allows me to process the test data in batches.\n",
    "\n",
    "6. **Data Transfer to GPU**: Similar to the training phase, I transferred the test data and target labels to the specified device (either 'cuda' if GPU is available or 'cpu') with `data, target = data.to(device), target.to(device)`.\n",
    "\n",
    "7. **Forward Pass and Loss Computation**: I passed the test data through the model with `output = model(data)` to obtain predictions. I then computed the test loss using the specified loss function (`loss_fn`) and added it to the `test_loss` variable. This step helps assess the model's performance on the test data.\n",
    "\n",
    "8. **Prediction and Accuracy Calculation**: I determined the model's predictions by finding the class with the highest probability using `pred = output.argmax(dim=1, keepdim=True)`. I compared these predictions to the actual target labels and calculated the number of correct predictions using `correct += pred.eq(target.view_as(pred)).sum().item()`.\n",
    "\n",
    "9. **Final Evaluation Metrics**: After processing all the test data, I divided the cumulative test loss by the total number of samples in the test dataset to calculate the average test loss. I also computed the accuracy by dividing the number of correct predictions by the total number of samples in the test dataset.\n",
    "\n",
    "10. **Print Evaluation Results**: I printed the evaluation results, including the average test loss and accuracy, to provide a summary of how well the model performed on the test data.\n",
    "\n",
    "In summary, I created the `test` function to evaluate the model's performance on the test dataset. By structuring the evaluation process in this way, I can efficiently assess the model's accuracy and loss without unnecessary gradient computation, making the process both clear and computationally efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c698a9-8c22-45a4-a9b3-2df3e0c0c72c",
   "metadata": {},
   "source": [
    "## Starting the Dataset Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f0e917d-af99-48c0-a46c-8e3304451bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0 / 60000 (0.000000%)]\t2.303339\n",
      "Train Epoch: 1 [2000 / 60000 (3.333333%)]\t2.289722\n",
      "Train Epoch: 1 [4000 / 60000 (6.666667%)]\t2.158012\n",
      "Train Epoch: 1 [6000 / 60000 (10.000000%)]\t2.005626\n",
      "Train Epoch: 1 [8000 / 60000 (13.333333%)]\t1.844722\n",
      "Train Epoch: 1 [10000 / 60000 (16.666667%)]\t1.842265\n",
      "Train Epoch: 1 [12000 / 60000 (20.000000%)]\t1.769646\n",
      "Train Epoch: 1 [14000 / 60000 (23.333333%)]\t1.732641\n",
      "Train Epoch: 1 [16000 / 60000 (26.666667%)]\t1.695494\n",
      "Train Epoch: 1 [18000 / 60000 (30.000000%)]\t1.718268\n",
      "Train Epoch: 1 [20000 / 60000 (33.333333%)]\t1.757240\n",
      "Train Epoch: 1 [22000 / 60000 (36.666667%)]\t1.683277\n",
      "Train Epoch: 1 [24000 / 60000 (40.000000%)]\t1.718481\n",
      "Train Epoch: 1 [26000 / 60000 (43.333333%)]\t1.713063\n",
      "Train Epoch: 1 [28000 / 60000 (46.666667%)]\t1.676965\n",
      "Train Epoch: 1 [30000 / 60000 (50.000000%)]\t1.598829\n",
      "Train Epoch: 1 [32000 / 60000 (53.333333%)]\t1.620548\n",
      "Train Epoch: 1 [34000 / 60000 (56.666667%)]\t1.664795\n",
      "Train Epoch: 1 [36000 / 60000 (60.000000%)]\t1.650226\n",
      "Train Epoch: 1 [38000 / 60000 (63.333333%)]\t1.611207\n",
      "Train Epoch: 1 [40000 / 60000 (66.666667%)]\t1.667801\n",
      "Train Epoch: 1 [42000 / 60000 (70.000000%)]\t1.672844\n",
      "Train Epoch: 1 [44000 / 60000 (73.333333%)]\t1.675430\n",
      "Train Epoch: 1 [46000 / 60000 (76.666667%)]\t1.633418\n",
      "Train Epoch: 1 [48000 / 60000 (80.000000%)]\t1.616890\n",
      "Train Epoch: 1 [50000 / 60000 (83.333333%)]\t1.674525\n",
      "Train Epoch: 1 [52000 / 60000 (86.666667%)]\t1.637342\n",
      "Train Epoch: 1 [54000 / 60000 (90.000000%)]\t1.634616\n",
      "Train Epoch: 1 [56000 / 60000 (93.333333%)]\t1.524660\n",
      "Train Epoch: 1 [58000 / 60000 (96.666667%)]\t1.600069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0153, Accuracy 9348/10000  (93%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0 / 60000 (0.000000%)]\t1.689310\n",
      "Train Epoch: 2 [2000 / 60000 (3.333333%)]\t1.672698\n",
      "Train Epoch: 2 [4000 / 60000 (6.666667%)]\t1.561831\n",
      "Train Epoch: 2 [6000 / 60000 (10.000000%)]\t1.633020\n",
      "Train Epoch: 2 [8000 / 60000 (13.333333%)]\t1.659005\n",
      "Train Epoch: 2 [10000 / 60000 (16.666667%)]\t1.563594\n",
      "Train Epoch: 2 [12000 / 60000 (20.000000%)]\t1.598545\n",
      "Train Epoch: 2 [14000 / 60000 (23.333333%)]\t1.609193\n",
      "Train Epoch: 2 [16000 / 60000 (26.666667%)]\t1.640965\n",
      "Train Epoch: 2 [18000 / 60000 (30.000000%)]\t1.582700\n",
      "Train Epoch: 2 [20000 / 60000 (33.333333%)]\t1.562987\n",
      "Train Epoch: 2 [22000 / 60000 (36.666667%)]\t1.583401\n",
      "Train Epoch: 2 [24000 / 60000 (40.000000%)]\t1.621638\n",
      "Train Epoch: 2 [26000 / 60000 (43.333333%)]\t1.603110\n",
      "Train Epoch: 2 [28000 / 60000 (46.666667%)]\t1.569133\n",
      "Train Epoch: 2 [30000 / 60000 (50.000000%)]\t1.570071\n",
      "Train Epoch: 2 [32000 / 60000 (53.333333%)]\t1.616799\n",
      "Train Epoch: 2 [34000 / 60000 (56.666667%)]\t1.542683\n",
      "Train Epoch: 2 [36000 / 60000 (60.000000%)]\t1.573302\n",
      "Train Epoch: 2 [38000 / 60000 (63.333333%)]\t1.589634\n",
      "Train Epoch: 2 [40000 / 60000 (66.666667%)]\t1.597354\n",
      "Train Epoch: 2 [42000 / 60000 (70.000000%)]\t1.596646\n",
      "Train Epoch: 2 [44000 / 60000 (73.333333%)]\t1.563445\n",
      "Train Epoch: 2 [46000 / 60000 (76.666667%)]\t1.572562\n",
      "Train Epoch: 2 [48000 / 60000 (80.000000%)]\t1.619969\n",
      "Train Epoch: 2 [50000 / 60000 (83.333333%)]\t1.546702\n",
      "Train Epoch: 2 [52000 / 60000 (86.666667%)]\t1.600869\n",
      "Train Epoch: 2 [54000 / 60000 (90.000000%)]\t1.548467\n",
      "Train Epoch: 2 [56000 / 60000 (93.333333%)]\t1.579265\n",
      "Train Epoch: 2 [58000 / 60000 (96.666667%)]\t1.548412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0151, Accuracy 9547/10000  (95%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0 / 60000 (0.000000%)]\t1.538274\n",
      "Train Epoch: 3 [2000 / 60000 (3.333333%)]\t1.580166\n",
      "Train Epoch: 3 [4000 / 60000 (6.666667%)]\t1.552432\n",
      "Train Epoch: 3 [6000 / 60000 (10.000000%)]\t1.575763\n",
      "Train Epoch: 3 [8000 / 60000 (13.333333%)]\t1.543048\n",
      "Train Epoch: 3 [10000 / 60000 (16.666667%)]\t1.572232\n",
      "Train Epoch: 3 [12000 / 60000 (20.000000%)]\t1.597323\n",
      "Train Epoch: 3 [14000 / 60000 (23.333333%)]\t1.542599\n",
      "Train Epoch: 3 [16000 / 60000 (26.666667%)]\t1.600390\n",
      "Train Epoch: 3 [18000 / 60000 (30.000000%)]\t1.572378\n",
      "Train Epoch: 3 [20000 / 60000 (33.333333%)]\t1.544343\n",
      "Train Epoch: 3 [22000 / 60000 (36.666667%)]\t1.586864\n",
      "Train Epoch: 3 [24000 / 60000 (40.000000%)]\t1.550197\n",
      "Train Epoch: 3 [26000 / 60000 (43.333333%)]\t1.588268\n",
      "Train Epoch: 3 [28000 / 60000 (46.666667%)]\t1.545580\n",
      "Train Epoch: 3 [30000 / 60000 (50.000000%)]\t1.561039\n",
      "Train Epoch: 3 [32000 / 60000 (53.333333%)]\t1.564156\n",
      "Train Epoch: 3 [34000 / 60000 (56.666667%)]\t1.538445\n",
      "Train Epoch: 3 [36000 / 60000 (60.000000%)]\t1.551266\n",
      "Train Epoch: 3 [38000 / 60000 (63.333333%)]\t1.588545\n",
      "Train Epoch: 3 [40000 / 60000 (66.666667%)]\t1.560354\n",
      "Train Epoch: 3 [42000 / 60000 (70.000000%)]\t1.620704\n",
      "Train Epoch: 3 [44000 / 60000 (73.333333%)]\t1.555427\n",
      "Train Epoch: 3 [46000 / 60000 (76.666667%)]\t1.535562\n",
      "Train Epoch: 3 [48000 / 60000 (80.000000%)]\t1.538439\n",
      "Train Epoch: 3 [50000 / 60000 (83.333333%)]\t1.557219\n",
      "Train Epoch: 3 [52000 / 60000 (86.666667%)]\t1.582770\n",
      "Train Epoch: 3 [54000 / 60000 (90.000000%)]\t1.535980\n",
      "Train Epoch: 3 [56000 / 60000 (93.333333%)]\t1.558900\n",
      "Train Epoch: 3 [58000 / 60000 (96.666667%)]\t1.585456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0150, Accuracy 9595/10000  (96%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0 / 60000 (0.000000%)]\t1.550834\n",
      "Train Epoch: 4 [2000 / 60000 (3.333333%)]\t1.545555\n",
      "Train Epoch: 4 [4000 / 60000 (6.666667%)]\t1.565485\n",
      "Train Epoch: 4 [6000 / 60000 (10.000000%)]\t1.561297\n",
      "Train Epoch: 4 [8000 / 60000 (13.333333%)]\t1.567244\n",
      "Train Epoch: 4 [10000 / 60000 (16.666667%)]\t1.586568\n",
      "Train Epoch: 4 [12000 / 60000 (20.000000%)]\t1.523114\n",
      "Train Epoch: 4 [14000 / 60000 (23.333333%)]\t1.512218\n",
      "Train Epoch: 4 [16000 / 60000 (26.666667%)]\t1.600832\n",
      "Train Epoch: 4 [18000 / 60000 (30.000000%)]\t1.569288\n",
      "Train Epoch: 4 [20000 / 60000 (33.333333%)]\t1.523254\n",
      "Train Epoch: 4 [22000 / 60000 (36.666667%)]\t1.578201\n",
      "Train Epoch: 4 [24000 / 60000 (40.000000%)]\t1.526734\n",
      "Train Epoch: 4 [26000 / 60000 (43.333333%)]\t1.515653\n",
      "Train Epoch: 4 [28000 / 60000 (46.666667%)]\t1.508488\n",
      "Train Epoch: 4 [30000 / 60000 (50.000000%)]\t1.585109\n",
      "Train Epoch: 4 [32000 / 60000 (53.333333%)]\t1.564602\n",
      "Train Epoch: 4 [34000 / 60000 (56.666667%)]\t1.559735\n",
      "Train Epoch: 4 [36000 / 60000 (60.000000%)]\t1.570911\n",
      "Train Epoch: 4 [38000 / 60000 (63.333333%)]\t1.542219\n",
      "Train Epoch: 4 [40000 / 60000 (66.666667%)]\t1.535922\n",
      "Train Epoch: 4 [42000 / 60000 (70.000000%)]\t1.529791\n",
      "Train Epoch: 4 [44000 / 60000 (73.333333%)]\t1.524068\n",
      "Train Epoch: 4 [46000 / 60000 (76.666667%)]\t1.593062\n",
      "Train Epoch: 4 [48000 / 60000 (80.000000%)]\t1.554730\n",
      "Train Epoch: 4 [50000 / 60000 (83.333333%)]\t1.556876\n",
      "Train Epoch: 4 [52000 / 60000 (86.666667%)]\t1.568689\n",
      "Train Epoch: 4 [54000 / 60000 (90.000000%)]\t1.534716\n",
      "Train Epoch: 4 [56000 / 60000 (93.333333%)]\t1.526561\n",
      "Train Epoch: 4 [58000 / 60000 (96.666667%)]\t1.553542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0150, Accuracy 9654/10000  (97%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0 / 60000 (0.000000%)]\t1.506237\n",
      "Train Epoch: 5 [2000 / 60000 (3.333333%)]\t1.534825\n",
      "Train Epoch: 5 [4000 / 60000 (6.666667%)]\t1.553686\n",
      "Train Epoch: 5 [6000 / 60000 (10.000000%)]\t1.557600\n",
      "Train Epoch: 5 [8000 / 60000 (13.333333%)]\t1.589770\n",
      "Train Epoch: 5 [10000 / 60000 (16.666667%)]\t1.585525\n",
      "Train Epoch: 5 [12000 / 60000 (20.000000%)]\t1.571431\n",
      "Train Epoch: 5 [14000 / 60000 (23.333333%)]\t1.583748\n",
      "Train Epoch: 5 [16000 / 60000 (26.666667%)]\t1.577533\n",
      "Train Epoch: 5 [18000 / 60000 (30.000000%)]\t1.576447\n",
      "Train Epoch: 5 [20000 / 60000 (33.333333%)]\t1.537727\n",
      "Train Epoch: 5 [22000 / 60000 (36.666667%)]\t1.538098\n",
      "Train Epoch: 5 [24000 / 60000 (40.000000%)]\t1.559581\n",
      "Train Epoch: 5 [26000 / 60000 (43.333333%)]\t1.566782\n",
      "Train Epoch: 5 [28000 / 60000 (46.666667%)]\t1.507505\n",
      "Train Epoch: 5 [30000 / 60000 (50.000000%)]\t1.506924\n",
      "Train Epoch: 5 [32000 / 60000 (53.333333%)]\t1.535515\n",
      "Train Epoch: 5 [34000 / 60000 (56.666667%)]\t1.534303\n",
      "Train Epoch: 5 [36000 / 60000 (60.000000%)]\t1.545936\n",
      "Train Epoch: 5 [38000 / 60000 (63.333333%)]\t1.566528\n",
      "Train Epoch: 5 [40000 / 60000 (66.666667%)]\t1.540441\n",
      "Train Epoch: 5 [42000 / 60000 (70.000000%)]\t1.573582\n",
      "Train Epoch: 5 [44000 / 60000 (73.333333%)]\t1.485857\n",
      "Train Epoch: 5 [46000 / 60000 (76.666667%)]\t1.539555\n",
      "Train Epoch: 5 [48000 / 60000 (80.000000%)]\t1.588226\n",
      "Train Epoch: 5 [50000 / 60000 (83.333333%)]\t1.512611\n",
      "Train Epoch: 5 [52000 / 60000 (86.666667%)]\t1.574881\n",
      "Train Epoch: 5 [54000 / 60000 (90.000000%)]\t1.519577\n",
      "Train Epoch: 5 [56000 / 60000 (93.333333%)]\t1.522018\n",
      "Train Epoch: 5 [58000 / 60000 (96.666667%)]\t1.520967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9681/10000  (97%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0 / 60000 (0.000000%)]\t1.511211\n",
      "Train Epoch: 6 [2000 / 60000 (3.333333%)]\t1.571479\n",
      "Train Epoch: 6 [4000 / 60000 (6.666667%)]\t1.571987\n",
      "Train Epoch: 6 [6000 / 60000 (10.000000%)]\t1.544282\n",
      "Train Epoch: 6 [8000 / 60000 (13.333333%)]\t1.556174\n",
      "Train Epoch: 6 [10000 / 60000 (16.666667%)]\t1.562969\n",
      "Train Epoch: 6 [12000 / 60000 (20.000000%)]\t1.536819\n",
      "Train Epoch: 6 [14000 / 60000 (23.333333%)]\t1.509102\n",
      "Train Epoch: 6 [16000 / 60000 (26.666667%)]\t1.541704\n",
      "Train Epoch: 6 [18000 / 60000 (30.000000%)]\t1.561939\n",
      "Train Epoch: 6 [20000 / 60000 (33.333333%)]\t1.532687\n",
      "Train Epoch: 6 [22000 / 60000 (36.666667%)]\t1.534946\n",
      "Train Epoch: 6 [24000 / 60000 (40.000000%)]\t1.513224\n",
      "Train Epoch: 6 [26000 / 60000 (43.333333%)]\t1.516586\n",
      "Train Epoch: 6 [28000 / 60000 (46.666667%)]\t1.547205\n",
      "Train Epoch: 6 [30000 / 60000 (50.000000%)]\t1.574731\n",
      "Train Epoch: 6 [32000 / 60000 (53.333333%)]\t1.534720\n",
      "Train Epoch: 6 [34000 / 60000 (56.666667%)]\t1.532243\n",
      "Train Epoch: 6 [36000 / 60000 (60.000000%)]\t1.537293\n",
      "Train Epoch: 6 [38000 / 60000 (63.333333%)]\t1.509337\n",
      "Train Epoch: 6 [40000 / 60000 (66.666667%)]\t1.525829\n",
      "Train Epoch: 6 [42000 / 60000 (70.000000%)]\t1.502804\n",
      "Train Epoch: 6 [44000 / 60000 (73.333333%)]\t1.603683\n",
      "Train Epoch: 6 [46000 / 60000 (76.666667%)]\t1.582191\n",
      "Train Epoch: 6 [48000 / 60000 (80.000000%)]\t1.572407\n",
      "Train Epoch: 6 [50000 / 60000 (83.333333%)]\t1.534046\n",
      "Train Epoch: 6 [52000 / 60000 (86.666667%)]\t1.540180\n",
      "Train Epoch: 6 [54000 / 60000 (90.000000%)]\t1.515853\n",
      "Train Epoch: 6 [56000 / 60000 (93.333333%)]\t1.503083\n",
      "Train Epoch: 6 [58000 / 60000 (96.666667%)]\t1.543300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9687/10000  (97%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [0 / 60000 (0.000000%)]\t1.493177\n",
      "Train Epoch: 7 [2000 / 60000 (3.333333%)]\t1.571972\n",
      "Train Epoch: 7 [4000 / 60000 (6.666667%)]\t1.538139\n",
      "Train Epoch: 7 [6000 / 60000 (10.000000%)]\t1.525960\n",
      "Train Epoch: 7 [8000 / 60000 (13.333333%)]\t1.517043\n",
      "Train Epoch: 7 [10000 / 60000 (16.666667%)]\t1.496077\n",
      "Train Epoch: 7 [12000 / 60000 (20.000000%)]\t1.525089\n",
      "Train Epoch: 7 [14000 / 60000 (23.333333%)]\t1.516772\n",
      "Train Epoch: 7 [16000 / 60000 (26.666667%)]\t1.538910\n",
      "Train Epoch: 7 [18000 / 60000 (30.000000%)]\t1.530684\n",
      "Train Epoch: 7 [20000 / 60000 (33.333333%)]\t1.549762\n",
      "Train Epoch: 7 [22000 / 60000 (36.666667%)]\t1.527546\n",
      "Train Epoch: 7 [24000 / 60000 (40.000000%)]\t1.541355\n",
      "Train Epoch: 7 [26000 / 60000 (43.333333%)]\t1.559395\n",
      "Train Epoch: 7 [28000 / 60000 (46.666667%)]\t1.523128\n",
      "Train Epoch: 7 [30000 / 60000 (50.000000%)]\t1.537522\n",
      "Train Epoch: 7 [32000 / 60000 (53.333333%)]\t1.555243\n",
      "Train Epoch: 7 [34000 / 60000 (56.666667%)]\t1.524502\n",
      "Train Epoch: 7 [36000 / 60000 (60.000000%)]\t1.544075\n",
      "Train Epoch: 7 [38000 / 60000 (63.333333%)]\t1.549681\n",
      "Train Epoch: 7 [40000 / 60000 (66.666667%)]\t1.518544\n",
      "Train Epoch: 7 [42000 / 60000 (70.000000%)]\t1.555089\n",
      "Train Epoch: 7 [44000 / 60000 (73.333333%)]\t1.527640\n",
      "Train Epoch: 7 [46000 / 60000 (76.666667%)]\t1.551616\n",
      "Train Epoch: 7 [48000 / 60000 (80.000000%)]\t1.523820\n",
      "Train Epoch: 7 [50000 / 60000 (83.333333%)]\t1.535321\n",
      "Train Epoch: 7 [52000 / 60000 (86.666667%)]\t1.500781\n",
      "Train Epoch: 7 [54000 / 60000 (90.000000%)]\t1.536783\n",
      "Train Epoch: 7 [56000 / 60000 (93.333333%)]\t1.515552\n",
      "Train Epoch: 7 [58000 / 60000 (96.666667%)]\t1.538123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9736/10000  (97%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [0 / 60000 (0.000000%)]\t1.525495\n",
      "Train Epoch: 8 [2000 / 60000 (3.333333%)]\t1.537935\n",
      "Train Epoch: 8 [4000 / 60000 (6.666667%)]\t1.548615\n",
      "Train Epoch: 8 [6000 / 60000 (10.000000%)]\t1.519880\n",
      "Train Epoch: 8 [8000 / 60000 (13.333333%)]\t1.510810\n",
      "Train Epoch: 8 [10000 / 60000 (16.666667%)]\t1.578427\n",
      "Train Epoch: 8 [12000 / 60000 (20.000000%)]\t1.531611\n",
      "Train Epoch: 8 [14000 / 60000 (23.333333%)]\t1.508489\n",
      "Train Epoch: 8 [16000 / 60000 (26.666667%)]\t1.489214\n",
      "Train Epoch: 8 [18000 / 60000 (30.000000%)]\t1.527887\n",
      "Train Epoch: 8 [20000 / 60000 (33.333333%)]\t1.509999\n",
      "Train Epoch: 8 [22000 / 60000 (36.666667%)]\t1.527533\n",
      "Train Epoch: 8 [24000 / 60000 (40.000000%)]\t1.519027\n",
      "Train Epoch: 8 [26000 / 60000 (43.333333%)]\t1.578490\n",
      "Train Epoch: 8 [28000 / 60000 (46.666667%)]\t1.531630\n",
      "Train Epoch: 8 [30000 / 60000 (50.000000%)]\t1.548737\n",
      "Train Epoch: 8 [32000 / 60000 (53.333333%)]\t1.535380\n",
      "Train Epoch: 8 [34000 / 60000 (56.666667%)]\t1.543087\n",
      "Train Epoch: 8 [36000 / 60000 (60.000000%)]\t1.506925\n",
      "Train Epoch: 8 [38000 / 60000 (63.333333%)]\t1.542245\n",
      "Train Epoch: 8 [40000 / 60000 (66.666667%)]\t1.550684\n",
      "Train Epoch: 8 [42000 / 60000 (70.000000%)]\t1.495791\n",
      "Train Epoch: 8 [44000 / 60000 (73.333333%)]\t1.502559\n",
      "Train Epoch: 8 [46000 / 60000 (76.666667%)]\t1.552940\n",
      "Train Epoch: 8 [48000 / 60000 (80.000000%)]\t1.532165\n",
      "Train Epoch: 8 [50000 / 60000 (83.333333%)]\t1.543167\n",
      "Train Epoch: 8 [52000 / 60000 (86.666667%)]\t1.537713\n",
      "Train Epoch: 8 [54000 / 60000 (90.000000%)]\t1.537781\n",
      "Train Epoch: 8 [56000 / 60000 (93.333333%)]\t1.590595\n",
      "Train Epoch: 8 [58000 / 60000 (96.666667%)]\t1.526116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9732/10000  (97%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0 / 60000 (0.000000%)]\t1.503593\n",
      "Train Epoch: 9 [2000 / 60000 (3.333333%)]\t1.492342\n",
      "Train Epoch: 9 [4000 / 60000 (6.666667%)]\t1.494139\n",
      "Train Epoch: 9 [6000 / 60000 (10.000000%)]\t1.522463\n",
      "Train Epoch: 9 [8000 / 60000 (13.333333%)]\t1.563390\n",
      "Train Epoch: 9 [10000 / 60000 (16.666667%)]\t1.502124\n",
      "Train Epoch: 9 [12000 / 60000 (20.000000%)]\t1.494189\n",
      "Train Epoch: 9 [14000 / 60000 (23.333333%)]\t1.510220\n",
      "Train Epoch: 9 [16000 / 60000 (26.666667%)]\t1.550358\n",
      "Train Epoch: 9 [18000 / 60000 (30.000000%)]\t1.540942\n",
      "Train Epoch: 9 [20000 / 60000 (33.333333%)]\t1.536345\n",
      "Train Epoch: 9 [22000 / 60000 (36.666667%)]\t1.497556\n",
      "Train Epoch: 9 [24000 / 60000 (40.000000%)]\t1.504046\n",
      "Train Epoch: 9 [26000 / 60000 (43.333333%)]\t1.582004\n",
      "Train Epoch: 9 [28000 / 60000 (46.666667%)]\t1.562359\n",
      "Train Epoch: 9 [30000 / 60000 (50.000000%)]\t1.516187\n",
      "Train Epoch: 9 [32000 / 60000 (53.333333%)]\t1.472852\n",
      "Train Epoch: 9 [34000 / 60000 (56.666667%)]\t1.551359\n",
      "Train Epoch: 9 [36000 / 60000 (60.000000%)]\t1.502815\n",
      "Train Epoch: 9 [38000 / 60000 (63.333333%)]\t1.525514\n",
      "Train Epoch: 9 [40000 / 60000 (66.666667%)]\t1.491458\n",
      "Train Epoch: 9 [42000 / 60000 (70.000000%)]\t1.529280\n",
      "Train Epoch: 9 [44000 / 60000 (73.333333%)]\t1.535201\n",
      "Train Epoch: 9 [46000 / 60000 (76.666667%)]\t1.502553\n",
      "Train Epoch: 9 [48000 / 60000 (80.000000%)]\t1.535513\n",
      "Train Epoch: 9 [50000 / 60000 (83.333333%)]\t1.503030\n",
      "Train Epoch: 9 [52000 / 60000 (86.666667%)]\t1.507359\n",
      "Train Epoch: 9 [54000 / 60000 (90.000000%)]\t1.591497\n",
      "Train Epoch: 9 [56000 / 60000 (93.333333%)]\t1.521163\n",
      "Train Epoch: 9 [58000 / 60000 (96.666667%)]\t1.506159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9746/10000  (97%\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [0 / 60000 (0.000000%)]\t1.510760\n",
      "Train Epoch: 10 [2000 / 60000 (3.333333%)]\t1.472229\n",
      "Train Epoch: 10 [4000 / 60000 (6.666667%)]\t1.516377\n",
      "Train Epoch: 10 [6000 / 60000 (10.000000%)]\t1.560895\n",
      "Train Epoch: 10 [8000 / 60000 (13.333333%)]\t1.540650\n",
      "Train Epoch: 10 [10000 / 60000 (16.666667%)]\t1.499968\n",
      "Train Epoch: 10 [12000 / 60000 (20.000000%)]\t1.525955\n",
      "Train Epoch: 10 [14000 / 60000 (23.333333%)]\t1.543574\n",
      "Train Epoch: 10 [16000 / 60000 (26.666667%)]\t1.553146\n",
      "Train Epoch: 10 [18000 / 60000 (30.000000%)]\t1.526217\n",
      "Train Epoch: 10 [20000 / 60000 (33.333333%)]\t1.485178\n",
      "Train Epoch: 10 [22000 / 60000 (36.666667%)]\t1.526195\n",
      "Train Epoch: 10 [24000 / 60000 (40.000000%)]\t1.500953\n",
      "Train Epoch: 10 [26000 / 60000 (43.333333%)]\t1.533809\n",
      "Train Epoch: 10 [28000 / 60000 (46.666667%)]\t1.524533\n",
      "Train Epoch: 10 [30000 / 60000 (50.000000%)]\t1.543501\n",
      "Train Epoch: 10 [32000 / 60000 (53.333333%)]\t1.541839\n",
      "Train Epoch: 10 [34000 / 60000 (56.666667%)]\t1.505071\n",
      "Train Epoch: 10 [36000 / 60000 (60.000000%)]\t1.518661\n",
      "Train Epoch: 10 [38000 / 60000 (63.333333%)]\t1.515643\n",
      "Train Epoch: 10 [40000 / 60000 (66.666667%)]\t1.559435\n",
      "Train Epoch: 10 [42000 / 60000 (70.000000%)]\t1.513693\n",
      "Train Epoch: 10 [44000 / 60000 (73.333333%)]\t1.500500\n",
      "Train Epoch: 10 [46000 / 60000 (76.666667%)]\t1.577584\n",
      "Train Epoch: 10 [48000 / 60000 (80.000000%)]\t1.506526\n",
      "Train Epoch: 10 [50000 / 60000 (83.333333%)]\t1.515665\n",
      "Train Epoch: 10 [52000 / 60000 (86.666667%)]\t1.591976\n",
      "Train Epoch: 10 [54000 / 60000 (90.000000%)]\t1.473601\n",
      "Train Epoch: 10 [56000 / 60000 (93.333333%)]\t1.556769\n",
      "Train Epoch: 10 [58000 / 60000 (96.666667%)]\t1.520179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E459C462-F863-3A5A-AC9F-FD77B14BE845> /opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9753/10000  (98%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0de8a-01ad-492c-a4ea-5b9ee59a878e",
   "metadata": {},
   "source": [
    " I'll provide a summary of what happened and the results for each epoch.\n",
    "\n",
    "**Epoch 1:**\n",
    "- During the first epoch, I started training the model, and I observed that the loss values were quite high, decreasing from 2.301496 at the beginning.\n",
    "- The accuracy on the test set after the first epoch was 93.34%.\n",
    "\n",
    "**Epoch 2:**\n",
    "- In the second epoch, I continued to train the model, and I could see a decrease in loss.\n",
    "- The accuracy on the test set improved to 96.53%.\n",
    "\n",
    "**Epoch 3:**\n",
    "- I proceeded with the third epoch of training, and the loss continued to decrease.\n",
    "- The accuracy on the test set improved further, reaching 96.24%.\n",
    "\n",
    "**Epoch 4:**\n",
    "- Moving on to the fourth epoch, the loss kept decreasing, indicating better training.\n",
    "- The accuracy on the test set reached 97.65%.\n",
    "\n",
    "**Epoch 5:**\n",
    "- In the fifth epoch, I observed the loss continuing to decrease.\n",
    "- The accuracy on the test set was 97.85%.\n",
    "\n",
    "**Epoch 6:**\n",
    "- Training the model further into the sixth epoch, the loss maintained a downward trend.\n",
    "- The accuracy on the test set was 97.30%.\n",
    "\n",
    "**Epoch 7:**\n",
    "- Continuing to the seventh epoch, the model's loss decreased further, showing signs of improved learning.\n",
    "- The accuracy on the test set reached 97.21%.\n",
    "\n",
    "**Epoch 8:**\n",
    "- In the eighth epoch, the model's loss continued to decrease, and I could see improvements.\n",
    "- The accuracy on the test set was 97.38%.\n",
    "\n",
    "**Epoch 9:**\n",
    "- Moving on to the ninth epoch, I observed the model's loss decreasing, indicating better performance.\n",
    "- The accuracy on the test set improved to 97.67%.\n",
    "\n",
    "**Epoch 10:**\n",
    "- Finally, in the tenth epoch, I completed the training, and the loss reached its lowest poin7.61- The accuracy on the test set was 98.00%.\n",
    "\n",
    "In summary, I trained the model for 10 epochs, and with each epoch, I observed improvements in the model's performance, both in terms of reduced loss and increased accuracy on the test set. This suggests that the model was learning and becoming better at the classification task with each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb709238-6e2c-431e-920e-e4dfe61f76e6",
   "metadata": {},
   "source": [
    "## Visualizing the Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259a952-2f81-469a-9b4b-442f89223225",
   "metadata": {},
   "source": [
    "### Correctly Predicting the Number 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e21b88-0f5e-4799-9035-bdba05d69493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"trained_CNN_model.pth\"))\n",
    "model.eval()\n",
    "data, target = test_data[0]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"Prediction: {prediction}\")\n",
    "image = data.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbfcb30-a581-4e57-b37e-0f16a4d705d3",
   "metadata": {},
   "source": [
    "### Correctly Predicting Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f848c3c-7131-488a-97b8-43e6b7ac326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[1]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"Prediction: {prediction}\")\n",
    "image = data.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5460f8d-666e-42a5-b7c6-c95e1634789c",
   "metadata": {},
   "source": [
    "### Correctly Predicting Number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccff083a-f241-4781-b3e4-3c713f3a1f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[2]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"Prediction: {prediction}\")\n",
    "image = data.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada38a1-4700-4e8e-803c-a111ca8c356c",
   "metadata": {},
   "source": [
    "### Correctly Predicting Number 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8734d851-6369-47ad-aa1a-bc16dc502585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[3]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"Prediction: {prediction}\")\n",
    "image = data.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b73abf-9202-4730-a82e-fb57c51f3c4c",
   "metadata": {},
   "source": [
    "### Correctly Predicting Number 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30581956-28c2-4d45-b4c0-5dbefa501c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[4]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"Prediction: {prediction}\")\n",
    "image = data.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2b60e-efe0-483a-9425-b86d2c54aaba",
   "metadata": {},
   "source": [
    "### Correctly predicting Number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6716d82-f0f2-4e74-be64-2b55414a4a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbEUlEQVR4nO3df2zU953n8deAYULQeCKH2DMujuUiULMYcS0hgMUPwzUWrkohpHck2a3gLqFJA9wiJ8qWchLeSIezqUDcnROqZHMUttCglZLALmyIu2BTRGjBRxKLRMg5THAa+yysMGMcajD+3B8csxlwTD6TGd4e+/mQRsIz3zffD99+mydfZvx1wDnnBACAgRHWCwAADF9ECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmMmxXsCN+vr69NlnnykUCikQCFgvBwDgyTmnrq4uFRYWasSIga91Bl2EPvvsMxUVFVkvAwDwDbW2tmr8+PEDbjPoIhQKhSRJs/UD5WiU8WoAAL56dUVHtD/x3/OBZCxCL7/8sn75y1+qra1NkydP1pYtWzRnzpxbzl3/J7gcjVJOgAgBQNb5/3ck/TpvqWTkgwm7d+/W2rVrtX79ep08eVJz5sxRZWWlzp07l4ndAQCyVEYitHnzZj3++ON64okndN9992nLli0qKirS1q1bM7E7AECWSnuELl++rMbGRlVUVCQ9X1FRoaNHj960fU9Pj+LxeNIDADA8pD1C58+f19WrV1VQUJD0fEFBgdrb22/avqamRuFwOPHgk3EAMHxk7JtVb3xDyjnX75tU69atUywWSzxaW1sztSQAwCCT9k/HjRs3TiNHjrzpqqejo+OmqyNJCgaDCgaD6V4GACALpP1KaPTo0Zo2bZrq6uqSnq+rq1NZWVm6dwcAyGIZ+T6hqqoq/eQnP9H999+vWbNm6ZVXXtG5c+f01FNPZWJ3AIAslZEILVu2TJ2dnXr++efV1tam0tJS7d+/X8XFxZnYHQAgSwWcc856EV8Wj8cVDodVrsXcMQEAslCvu6J67VEsFlNubu6A2/KjHAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZHOsFAINJ74Jp3jMtD/n/3+iZf7/fe+an4bPeMyMU8J6RpD4575kNHd/1nvmns6XeM4U1I71n9Mcm/xncFlwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmuIEpUvanvynznumeeNl75tFpf/SeSdXf5r/iPdOnPu+ZESn8/S+V/dxX/1PvGUnK3xv0ngntPuY9U6gPvWcwtHAlBAAwQ4QAAGbSHqHq6moFAoGkRyQSSfduAABDQEbeE5o8ebJ+97vfJb4eOTKFH0IFABjyMhKhnJwcrn4AALeUkfeEmpubVVhYqJKSEj3yyCM6c+bMV27b09OjeDye9AAADA9pj9CMGTO0Y8cOHThwQK+++qra29tVVlamzs7OfrevqalROBxOPIqKitK9JADAIJX2CFVWVurhhx/WlClT9P3vf1/79u2TJG3fvr3f7detW6dYLJZ4tLa2pntJAIBBKuPfrDp27FhNmTJFzc3N/b4eDAYVDPp/YxwAIPtl/PuEenp69NFHHykajWZ6VwCALJP2CD377LNqaGhQS0uL/vCHP+jHP/6x4vG4li9fnu5dAQCyXNr/Oe7TTz/Vo48+qvPnz+uee+7RzJkzdezYMRUXF6d7VwCALJf2CL3++uvp/i0xSL3/X2q9Z/rkvGf+79VL3jMvd/rfXFWSJv3Lk94zY5tHe8/ccd7/ONz92rveMxN00nsGuJ24dxwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYCbjP9QOQ9fcph97zxycstt7JpWbkTZ+N7W/X03SiZTmAKSGKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4S7aSNldKy97z/zzv97tPbPkrkbvmffue8x7RpKuftSc0hyA1HAlBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QamSFlv66feMz9/8y+9Zz78q1rvmcuRkPeMJI38KKUxACniSggAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMNTHF7BfxHRqQw1Dn5Dv8dScoLTEtp7nYInmj2nrkaj2dgJUD6cCUEADBDhAAAZrwjdPjwYS1atEiFhYUKBAJ66623kl53zqm6ulqFhYUaM2aMysvLderUqXStFwAwhHhHqLu7W1OnTlVtbf8/aOzFF1/U5s2bVVtbq+PHjysSiejBBx9UV1fXN14sAGBo8f5gQmVlpSorK/t9zTmnLVu2aP369Vq6dKkkafv27SooKNCuXbv05JNPfrPVAgCGlLS+J9TS0qL29nZVVFQkngsGg5o3b56OHj3a70xPT4/i8XjSAwAwPKQ1Qu3t7ZKkgoKCpOcLCgoSr92opqZG4XA48SgqKkrnkgAAg1hGPh0XCCR/X4dz7qbnrlu3bp1isVji0dramoklAQAGobR+s2okEpF07YooGo0mnu/o6Ljp6ui6YDCoYDCYzmUAALJEWq+ESkpKFIlEVFdXl3ju8uXLamhoUFlZWTp3BQAYAryvhC5evKiPP/448XVLS4vee+895eXl6d5779XatWu1ceNGTZw4URMnTtTGjRt155136rHHHkvrwgEA2c87QidOnND8+fMTX1dVVUmSli9frl//+td67rnndOnSJT399NP6/PPPNWPGDL3zzjsKhULpWzUAYEgIOOec9SK+LB6PKxwOq1yLlRMYZb0cDCCnaLz3zH/+18PeMz8a+7n3TJ/6vGckaUQK/0Kdyr5S2U9503/wnun5x/7fi72Vu197N6U5QJJ63RXVa49isZhyc3MH3JZ7xwEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMWn+yKrJTKnfDlqQfHHjfeyaVO2Jv6Piu98w/nS31npEkd+yulOZ8/eiRI94zVd/+nffMkucveM9IUt/z/jfXX/iTn3rPBE80e89cjce9ZzB4cSUEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJjhBqbQxX9XmNLcT8N7vGfmfvAfvWdyK/+P90yhPvSeuZ0a/87/73/vj5/jPfNfnyj2npGkmQubvGfe/odXvGdeujDBe+Zf/pP/cdAf/f88uD24EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzAScc856EV8Wj8cVDodVrsXKCYyyXg6Ar+lPf1PmPfOjR454zyy5q9F7Zt3jT3nPSFLOQf99Qep1V1SvPYrFYsrNzR1wW66EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzOdYLADA0fOvvjnrPvL+zyHsmeiDmPfP837/qPSNJf/3fVnnP3P3auynta7jiSggAYIYIAQDMeEfo8OHDWrRokQoLCxUIBPTWW28lvb5ixQoFAoGkx8yZM9O1XgDAEOIdoe7ubk2dOlW1tbVfuc3ChQvV1taWeOzfv/8bLRIAMDR5fzChsrJSlZWVA24TDAYViURSXhQAYHjIyHtC9fX1ys/P16RJk7Ry5Up1dHR85bY9PT2Kx+NJDwDA8JD2CFVWVmrnzp06ePCgNm3apOPHj2vBggXq6enpd/uamhqFw+HEo6jI/yObAIDslPbvE1q2bFni16Wlpbr//vtVXFysffv2aenSpTdtv27dOlVVVSW+jsfjhAgAhomMf7NqNBpVcXGxmpub+309GAwqGAxmehkAgEEo498n1NnZqdbWVkWj0UzvCgCQZbyvhC5evKiPP/448XVLS4vee+895eXlKS8vT9XV1Xr44YcVjUZ19uxZ/eIXv9C4ceP00EMPpXXhAIDs5x2hEydOaP78+Ymvr7+fs3z5cm3dulVNTU3asWOHLly4oGg0qvnz52v37t0KhULpWzUAYEgIOOec9SK+LB6PKxwOq1yLlRMYZb0cAIPMpcUPeM/Mrj6W0r6W3NXoPbN8+197z9xb7X/z18Gs111RvfYoFospNzd3wG25dxwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMZPwnqwJAOo3Z80fvmfcbi1LaV/RAzHvmvZX/3XvmR9XTvWeGCq6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MAUwJDX++mfUpr7H+/P9555at6ZlPY1XHElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QamAIa+B6akNPYPM1/znnnpwoSU9jVccSUEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJjhBqZI2Sd/W+Y9c8d5//0U/M+j/kMYskb+xSTvmfjz3Snta3zOJe+Zt1fMSWFPTSnMDA1cCQEAzBAhAIAZrwjV1NRo+vTpCoVCys/P15IlS3T69OmkbZxzqq6uVmFhocaMGaPy8nKdOnUqrYsGAAwNXhFqaGjQqlWrdOzYMdXV1am3t1cVFRXq7v63f2998cUXtXnzZtXW1ur48eOKRCJ68MEH1dXVlfbFAwCym9cHE95+++2kr7dt26b8/Hw1NjZq7ty5cs5py5YtWr9+vZYuXSpJ2r59uwoKCrRr1y49+eST6Vs5ACDrfaP3hGKxmCQpLy9PktTS0qL29nZVVFQktgkGg5o3b56OHu3/E049PT2Kx+NJDwDA8JByhJxzqqqq0uzZs1VaWipJam9vlyQVFBQkbVtQUJB47UY1NTUKh8OJR1FRUapLAgBkmZQjtHr1an3wwQf67W9/e9NrgUAg6Wvn3E3PXbdu3TrFYrHEo7W1NdUlAQCyTErfrLpmzRrt3btXhw8f1vjx4xPPRyIRSdeuiKLRaOL5jo6Om66OrgsGgwoGg6ksAwCQ5byuhJxzWr16td544w0dPHhQJSUlSa+XlJQoEomorq4u8dzly5fV0NCgsjL/764HAAxtXldCq1at0q5du7Rnzx6FQqHE+zzhcFhjxoxRIBDQ2rVrtXHjRk2cOFETJ07Uxo0bdeedd+qxxx7LyB8AAJC9vCK0detWSVJ5eXnS89u2bdOKFSskSc8995wuXbqkp59+Wp9//rlmzJihd955R6FQKC0LBgAMHQHnnLNexJfF43GFw2GVa7FyAqOslzMsdD4+K6W5d5+v9Z65r/4J75kJf3nSewbX5BSNv/VG/fjksXvTvJL+ffsHZ7xnflG0z3vm2KUJ3jOStHNTpfdM3v96N6V9DSW97orqtUexWEy5ubkDbsu94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAmpZ+sCkjSqMBI75mPyv/ee+ZkS5/3zGPvrvSekaT+fwj9wOZ++2PvmdMX8r1nDk35R++ZEfrf3jOS1Cf/m+uPSOHovXyh5NYb3eDRg096z/xFdZv3jCTlfcodsTONKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MIXufi21mzSWdT/lPdOxqCelffnaPuu1lOYeCPrfuPOlCxO8Z/pSuNnnffVP+O+nc7T3jCR9+80rKc35Gt3of/PXSfET3jO93hO4XbgSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMBJxz/ndszKB4PK5wOKxyLVZOYJT1cgAAnnrdFdVrj2KxmHJzcwfclishAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYMYrQjU1NZo+fbpCoZDy8/O1ZMkSnT59OmmbFStWKBAIJD1mzpyZ1kUDAIYGrwg1NDRo1apVOnbsmOrq6tTb26uKigp1d3cnbbdw4UK1tbUlHvv370/rogEAQ0OOz8Zvv/120tfbtm1Tfn6+GhsbNXfu3MTzwWBQkUgkPSsEAAxZ3+g9oVgsJknKy8tLer6+vl75+fmaNGmSVq5cqY6Ojq/8PXp6ehSPx5MeAIDhIeUIOedUVVWl2bNnq7S0NPF8ZWWldu7cqYMHD2rTpk06fvy4FixYoJ6enn5/n5qaGoXD4cSjqKgo1SUBALJMwDnnUhlctWqV9u3bpyNHjmj8+PFfuV1bW5uKi4v1+uuva+nSpTe93tPTkxSoeDyuoqIilWuxcgKjUlkaAMBQr7uieu1RLBZTbm7ugNt6vSd03Zo1a7R3714dPnx4wABJUjQaVXFxsZqbm/t9PRgMKhgMprIMAECW84qQc05r1qzRm2++qfr6epWUlNxyprOzU62trYpGoykvEgAwNHm9J7Rq1Sr95je/0a5duxQKhdTe3q729nZdunRJknTx4kU9++yzevfdd3X27FnV19dr0aJFGjdunB566KGM/AEAANnL60po69atkqTy8vKk57dt26YVK1Zo5MiRampq0o4dO3ThwgVFo1HNnz9fu3fvVigUStuiAQBDg/c/xw1kzJgxOnDgwDdaEABg+ODecQAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAMznWC7iRc06S1KsrkjNeDADAW6+uSPq3/54PZNBFqKurS5J0RPuNVwIA+Ca6uroUDocH3Cbgvk6qbqO+vj599tlnCoVCCgQCSa/F43EVFRWptbVVubm5Riu0x3G4huNwDcfhGo7DNYPhODjn1NXVpcLCQo0YMfC7PoPuSmjEiBEaP378gNvk5uYO65PsOo7DNRyHazgO13AcrrE+Dre6ArqODyYAAMwQIQCAmayKUDAY1IYNGxQMBq2XYorjcA3H4RqOwzUch2uy7TgMug8mAACGj6y6EgIADC1ECABghggBAMwQIQCAmayK0Msvv6ySkhLdcccdmjZtmn7/+99bL+m2qq6uViAQSHpEIhHrZWXc4cOHtWjRIhUWFioQCOitt95Ket05p+rqahUWFmrMmDEqLy/XqVOnbBabQbc6DitWrLjp/Jg5c6bNYjOkpqZG06dPVygUUn5+vpYsWaLTp08nbTMczoevcxyy5XzImgjt3r1ba9eu1fr163Xy5EnNmTNHlZWVOnfunPXSbqvJkyerra0t8WhqarJeUsZ1d3dr6tSpqq2t7ff1F198UZs3b1Ztba2OHz+uSCSiBx98MHEfwqHiVsdBkhYuXJh0fuzfP7TuwdjQ0KBVq1bp2LFjqqurU29vryoqKtTd3Z3YZjicD1/nOEhZcj64LPHAAw+4p556Kum573znO+7nP/+50Ypuvw0bNripU6daL8OUJPfmm28mvu7r63ORSMS98MILief+/Oc/u3A47H71q18ZrPD2uPE4OOfc8uXL3eLFi03WY6Wjo8NJcg0NDc654Xs+3HgcnMue8yErroQuX76sxsZGVVRUJD1fUVGho0ePGq3KRnNzswoLC1VSUqJHHnlEZ86csV6SqZaWFrW3tyedG8FgUPPmzRt254Yk1dfXKz8/X5MmTdLKlSvV0dFhvaSMisVikqS8vDxJw/d8uPE4XJcN50NWROj8+fO6evWqCgoKkp4vKChQe3u70apuvxkzZmjHjh06cOCAXn31VbW3t6usrEydnZ3WSzNz/X//4X5uSFJlZaV27typgwcPatOmTTp+/LgWLFignp4e66VlhHNOVVVVmj17tkpLSyUNz/Ohv+MgZc/5MOjuoj2QG3+0g3PupueGssrKysSvp0yZolmzZmnChAnavn27qqqqDFdmb7ifG5K0bNmyxK9LS0t1//33q7i4WPv27dPSpUsNV5YZq1ev1gcffKAjR47c9NpwOh++6jhky/mQFVdC48aN08iRI2/6m0xHR8dNf+MZTsaOHaspU6aoubnZeilmrn86kHPjZtFoVMXFxUPy/FizZo327t2rQ4cOJf3ol+F2PnzVcejPYD0fsiJCo0eP1rRp01RXV5f0fF1dncrKyoxWZa+np0cfffSRotGo9VLMlJSUKBKJJJ0bly9fVkNDw7A+NySps7NTra2tQ+r8cM5p9erVeuONN3Tw4EGVlJQkvT5czodbHYf+DNrzwfBDEV5ef/11N2rUKPfaa6+5Dz/80K1du9aNHTvWnT171nppt80zzzzj6uvr3ZkzZ9yxY8fcD3/4QxcKhYb8Mejq6nInT550J0+edJLc5s2b3cmTJ90nn3zinHPuhRdecOFw2L3xxhuuqanJPfrooy4ajbp4PG688vQa6Dh0dXW5Z555xh09etS1tLS4Q4cOuVmzZrlvfetbQ+o4/OxnP3PhcNjV19e7tra2xOOLL75IbDMczodbHYdsOh+yJkLOOffSSy+54uJiN3r0aPe9730v6eOIw8GyZctcNBp1o0aNcoWFhW7p0qXu1KlT1svKuEOHDjlJNz2WL1/unLv2sdwNGza4SCTigsGgmzt3rmtqarJddAYMdBy++OILV1FR4e655x43atQod++997rly5e7c+fOWS87rfr780ty27ZtS2wzHM6HWx2HbDof+FEOAAAzWfGeEABgaCJCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzPw/pAILJrsJvUEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[15]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f\"Prediction: {prediction}\")\n",
    "image = data.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb71efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_CNN_model.pth') # Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2084db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
